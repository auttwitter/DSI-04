{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Lab: Fun with Neural Nets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a procedure for building a neural network to recognize handwritten digits.  The data is from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data), and you will submit your results to Kaggle to test how well you did!\n",
    "\n",
    "1. Load the training data (`train.csv`) from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data)\n",
    "2. Setup X and y (feature matrix and target vector).\n",
    "3. Split X and y into train and test subsets.\n",
    "4. Preprocess your data:\n",
    "\n",
    "   - When dealing with image data, you need to normalize your `X` by dividing each value by the max value of a pixel (255).\n",
    "   - Since this is a multiclass classification problem, keras needs `y` to be a one-hot encoded matrix.\n",
    "   \n",
    "5. Create your network:\n",
    "   - Remember that for multi-class classification you need a softmax activation function on the output layer.\n",
    "   - You may want to consider using regularization or dropout to improve performance.\n",
    "   \n",
    "6. Train your network.\n",
    "7. If you are unhappy with your model performance, try to tighten up your model by adding hidden layers, adding hidden layer units, chaining the activation functions on the hidden layers, etc.\n",
    "8. Load in [Kaggle's](https://www.kaggle.com/c/digit-recognizer/data) `test.csv`.\n",
    "9. Create your predictions (these should be numbers in the range 0-9).\n",
    "10. Save your predictions and submit them to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For this lab, you should complete the above sequence of steps for **_at least_** two of the four **\"configurations\"**:\n",
    "\n",
    "1. Using a `tensorflow` network\n",
    "2. Using a `keras` convolutional network\n",
    "3. Using a `keras` network with regularization\n",
    "4. Using a `tensorflow` convolutional network (we did _not_ cover this in class!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "np.random.seed(42)        # Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the training data (`train.csv`) from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data)\n",
    "# train_data.shape = (42000, 785)\n",
    "# test_data.shape = (28000, 784)\n",
    "train_data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup X and y (feature matrix and target vector).\n",
    "X = train_data.drop(columns = ['label'])\n",
    "y = train_data['label']\n",
    "\n",
    "# 4. Preprocess your data: I think it's easier if doing this before Split\n",
    "# Normalize X\n",
    "X = X / 255.0\n",
    "\n",
    "# One-hot encode y\n",
    "ec = OneHotEncoder(sparse_output = False)\n",
    "y = ec.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split X and y into train and test subsets.\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create your network:\n",
    "\n",
    "model = Sequential([Input(shape = (784,))\n",
    "                    , Dense(128, activation = 'relu', kernel_regularizer = 'l2')     # Hidden Layer 1\n",
    "                    , Dropout(0.3)                                                   # Drop for prevent overfitting\n",
    "                    , Dense(64, activation = 'relu')                                 # Hidden Layer 2\n",
    "                    , Dense(10, activation = 'softmax')                              # Output layer, use softmax for multiclass\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam'\n",
    "              , loss='categorical_crossentropy'                                      # For multiclass\n",
    "              , metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 1.1834 - val_accuracy: 0.9267 - val_loss: 0.4024\n",
      "Epoch 2/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.4476 - val_accuracy: 0.9371 - val_loss: 0.3606\n",
      "Epoch 3/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.4184 - val_accuracy: 0.9551 - val_loss: 0.3115\n",
      "Epoch 4/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.4020 - val_accuracy: 0.9554 - val_loss: 0.3003\n",
      "Epoch 5/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.3955 - val_accuracy: 0.9588 - val_loss: 0.2952\n",
      "Epoch 6/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.3894 - val_accuracy: 0.9604 - val_loss: 0.2969\n",
      "Epoch 7/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9298 - loss: 0.3842 - val_accuracy: 0.9621 - val_loss: 0.2824\n",
      "Epoch 8/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9299 - loss: 0.3781 - val_accuracy: 0.9579 - val_loss: 0.2955\n",
      "Epoch 9/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.3782 - val_accuracy: 0.9618 - val_loss: 0.2927\n",
      "Epoch 10/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9313 - loss: 0.3834 - val_accuracy: 0.9610 - val_loss: 0.2932\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    X                                   # Input data (features)\n",
    "    , y                                 # Target/class labels (one-hot encoded classes 0-9)\n",
    "    , batch_size = 32                   # Number of the samples processed in each batch\n",
    "    , epochs = 10                       # Number of complete passes through the dataset\n",
    "    ,  validation_data = (X_dev, y_dev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Load in [Kaggle's](https://www.kaggle.com/c/digit-recognizer/data) `test.csv`.\n",
    "# Since the test_data has only features, we directly apply normalization\n",
    "test_data = pd.read_csv('data/test.csv').values / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1065687e-06, 3.1684788e-08, 9.9978656e-01, ..., 4.9466449e-05,\n",
       "        3.4187653e-06, 1.6961869e-07],\n",
       "       [9.9988997e-01, 7.8008560e-09, 5.0151622e-05, ..., 7.4794144e-07,\n",
       "        1.4477371e-07, 1.1240304e-06],\n",
       "       [9.4017538e-05, 3.3323202e-04, 4.2328381e-04, ..., 9.3259672e-03,\n",
       "        6.0876675e-02, 8.9839578e-01],\n",
       "       ...,\n",
       "       [8.7290974e-09, 7.8401001e-07, 2.1090504e-05, ..., 1.6935579e-07,\n",
       "        1.1264300e-04, 1.0540335e-04],\n",
       "       [4.8519458e-05, 9.3332233e-07, 3.2907927e-05, ..., 2.9163393e-03,\n",
       "        3.0330857e-04, 9.7573030e-01],\n",
       "       [6.0195080e-06, 2.2286278e-07, 9.9854183e-01, ..., 4.4653140e-04,\n",
       "        6.6090215e-05, 1.9844394e-05]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = np.argmax(predictions, axis = 1)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': range(1, len(predicted_labels) + 1), 'Label': predicted_labels})\n",
    "submission.to_csv('data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.95300 on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([Input(shape = (784,))\n",
    "                    , Dense(256, activation = 'relu', kernel_regularizer = 'l2')     # Hidden Layer 1\n",
    "                    , Dropout(0.3)                                                   # Drop for prevent overfitting\n",
    "                    , Dense(256, activation = 'relu')                                 # Hidden Layer 2\n",
    "                   # , Dropout(0.3)                                                   # Drop for prevent overfitting\n",
    "                    , Dense(256, activation = 'relu')                                 # Hidden Layer 3\n",
    "                    , Dense(10, activation = 'softmax')                              # Output layer, use softmax for multiclass\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer = 'adam'\n",
    "              , loss='categorical_crossentropy'                                      # For multiclass\n",
    "              , metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 1.2816 - val_accuracy: 0.9313 - val_loss: 0.4295\n",
      "Epoch 2/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9181 - loss: 0.4802 - val_accuracy: 0.9504 - val_loss: 0.3591\n",
      "Epoch 3/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.4351 - val_accuracy: 0.9463 - val_loss: 0.3638\n",
      "Epoch 4/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9283 - loss: 0.4227 - val_accuracy: 0.9589 - val_loss: 0.3266\n",
      "Epoch 5/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9289 - loss: 0.4162 - val_accuracy: 0.9621 - val_loss: 0.3112\n",
      "Epoch 6/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9325 - loss: 0.3992 - val_accuracy: 0.9555 - val_loss: 0.3291\n",
      "Epoch 7/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 0.3894 - val_accuracy: 0.9606 - val_loss: 0.3079\n",
      "Epoch 8/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.3795 - val_accuracy: 0.9629 - val_loss: 0.2930\n",
      "Epoch 9/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.3818 - val_accuracy: 0.9676 - val_loss: 0.2702\n",
      "Epoch 10/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9348 - loss: 0.3767 - val_accuracy: 0.9587 - val_loss: 0.2925\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(\n",
    "    X                                   # Input data (features)\n",
    "    , y                                 # Target/class labels (one-hot encoded classes 0-9)\n",
    "    , batch_size = 32                   # Number of the samples processed in each batch\n",
    "    , epochs = 10                       # Number of complete passes through the dataset\n",
    "    ,  validation_data = (X_dev, y_dev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = model2.predict(test_data)\n",
    "predicted_labels2 = np.argmax(predictions2, axis=1)\n",
    "predicted_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame({'ImageId': range(1, len(predicted_labels2) + 1), 'Label': predicted_labels2})\n",
    "submission2.to_csv('data/submission2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.94932"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/kaggle.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
